{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                       Open         High          Low        Close  \\\n",
      "Ticker               RELIANCE.NS  RELIANCE.NS  RELIANCE.NS  RELIANCE.NS   \n",
      "Datetime                                                                  \n",
      "2024-12-09 09:30:00  1311.050049  1314.449951  1309.199951  1309.849976   \n",
      "\n",
      "Price                    Volume  \n",
      "Ticker              RELIANCE.NS  \n",
      "Datetime                         \n",
      "2024-12-09 09:30:00     1326135  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "stock_symbol = \"RELIANCE.NS\"\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=50)  # 2 months (roughly 60 days)\n",
    "\n",
    "# Convert to strings in the format yfinance expects\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "data = yf.download(stock_symbol, start=start_date_str, end=end_date_str, interval=\"30m\")\n",
    "data = data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "print(data.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, data, sequence_length = 15):\n",
    "        self.data = data\n",
    "\n",
    "        #Scaling data to range (0,1)\n",
    "        self.scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        self.scaled_data = self.scaler.fit_transform(data)\n",
    "\n",
    "        self.images = []\n",
    "        self.output = []\n",
    "        for i in range (len(data) - sequence_length):\n",
    "            window = self.scaled_data[i : i + sequence_length, : ]\n",
    "            self.images.append(window)\n",
    "            self.output.append(self.scaled_data[i + sequence_length, 3])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.images[idx]\n",
    "        y = self.output[idx]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 15, 5])\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 15\n",
    "batch_size = 16\n",
    "\n",
    "dataset_instance = dataset(data.values, sequence_length = sequence_length)\n",
    "trainloader = DataLoader(dataset=dataset_instance, batch_size = batch_size, drop_last = True)\n",
    "\n",
    "for idx, (x,y) in enumerate(trainloader):\n",
    "    print(x.shape)\n",
    "    if idx==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_for_time_series(nn.Module):\n",
    "    def __init__(self, hidden_size, out_size, dropout_prob = 0.2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = hidden_size, kernel_size = (3,3), stride = 1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = (2,2), stride = 1)\n",
    "        self.drop = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = hidden_size, out_channels = out_size, kernel_size = (3,3), stride = 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(out_size * 12 * 2, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.drop(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.drop(x)\n",
    "\n",
    "        x = torch.flatten(x,1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "\n",
    "model = cnn_for_time_series(hidden_size1, hidden_size2, dropout_prob=0.3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.002)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch  0  is :  0.05537488860621428\n",
      "Loss at epoch  1  is :  0.018149829246491816\n",
      "Loss at epoch  2  is :  0.017399850553677727\n",
      "Loss at epoch  3  is :  0.015117100381758064\n",
      "Loss at epoch  4  is :  0.014632390181456381\n",
      "Loss at epoch  5  is :  0.01666561923533057\n",
      "Loss at epoch  6  is :  0.01478029698288689\n",
      "Loss at epoch  7  is :  0.013289067389753958\n",
      "Loss at epoch  8  is :  0.013471533010791367\n",
      "Loss at epoch  9  is :  0.012809016732110953\n",
      "Loss at epoch  10  is :  0.014223046465000758\n",
      "Loss at epoch  11  is :  0.014307311532320455\n",
      "Loss at epoch  12  is :  0.01321884109347593\n",
      "Loss at epoch  13  is :  0.011967022554017603\n",
      "Loss at epoch  14  is :  0.013148543589826053\n",
      "Loss at epoch  15  is :  0.01291497612207119\n",
      "Loss at epoch  16  is :  0.011540470960123153\n",
      "Loss at epoch  17  is :  0.011131424631457776\n",
      "Loss at epoch  18  is :  0.012439343898828762\n",
      "Loss at epoch  19  is :  0.010402645430682847\n",
      "Loss at epoch  20  is :  0.01106165965514568\n",
      "Loss at epoch  21  is :  0.01240012226238226\n",
      "Loss at epoch  22  is :  0.01125887367137087\n",
      "Loss at epoch  23  is :  0.010757209117097469\n",
      "Loss at epoch  24  is :  0.010500732358195819\n",
      "Loss at epoch  25  is :  0.0113305611157557\n",
      "Loss at epoch  26  is :  0.00962702055403497\n",
      "Loss at epoch  27  is :  0.011643636050090814\n",
      "Loss at epoch  28  is :  0.010813229891937226\n",
      "Loss at epoch  29  is :  0.010448043414119942\n",
      "Loss at epoch  30  is :  0.010170903221781677\n",
      "Loss at epoch  31  is :  0.010332716648311665\n",
      "Loss at epoch  32  is :  0.008889745964552276\n",
      "Loss at epoch  33  is :  0.009255395188423185\n",
      "Loss at epoch  34  is :  0.010789977522411695\n",
      "Loss at epoch  35  is :  0.009792151395231485\n",
      "Loss at epoch  36  is :  0.009236632729880512\n",
      "Loss at epoch  37  is :  0.010013668448664248\n",
      "Loss at epoch  38  is :  0.008828147236878673\n",
      "Loss at epoch  39  is :  0.010546983336098492\n",
      "Loss at epoch  40  is :  0.00943487427624253\n",
      "Loss at epoch  41  is :  0.009666738648472043\n",
      "Loss at epoch  42  is :  0.009700911289352613\n",
      "Loss at epoch  43  is :  0.009544293621729594\n",
      "Loss at epoch  44  is :  0.009073587512830272\n",
      "Loss at epoch  45  is :  0.01042458461112498\n",
      "Loss at epoch  46  is :  0.008255621777304137\n",
      "Loss at epoch  47  is :  0.009565702988766134\n",
      "Loss at epoch  48  is :  0.00829023529756038\n",
      "Loss at epoch  49  is :  0.008486517845691802\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "for epoch in range (num_epochs):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for  x, y in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y.view(-1,1))\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Loss at epoch \",epoch,\" is : \", epoch_loss/len(trainloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Close :  tensor(0.5849)\n",
      "Predicted Close: [[0.61950976]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = x[5]  # Use the last batch as a test input\n",
    "    test_output = y[5]\n",
    "    print('Actual Close : ',test_output)\n",
    "    test_input = test_input.unsqueeze(0)\n",
    "    prediction = model(test_input)\n",
    "    predicted_close = prediction.numpy()  # Get the predicted 'Close' price\n",
    "    print(f\"Predicted Close: {predicted_close}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 15, 5])\n",
      "shape :  torch.Size([1, 1])\n",
      "Predicted Close Price: ₹1252.18\n",
      "Actual Close Price: ₹1244.35\n",
      "Prediction Error: ₹7.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\GIDEON\\AppData\\Local\\Temp\\ipykernel_29340\\3611095557.py:37: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  actual_close = float(data['Close'].iloc[-1])\n"
     ]
    }
   ],
   "source": [
    "data = yf.download(stock_symbol, period=\"5d\", interval=\"30m\")\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "# Get the last 15 data points\n",
    "last_15_data = data.tail(15)\n",
    "\n",
    "pred_input = last_15_data.loc[:,['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "scaled_input = scaler.fit_transform(pred_input)\n",
    "\n",
    "\n",
    "\n",
    "pred_tensor = torch.tensor(scaled_input , dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_tensor = pred_tensor.unsqueeze(0)\n",
    "    pred_tensor = pred_tensor.unsqueeze(1)\n",
    "    print(pred_tensor.shape)\n",
    "    pred_output = model(pred_tensor)\n",
    "    print(\"shape : \", pred_output.shape)\n",
    "\n",
    "    # predicted_output = pred_output.numpy()\n",
    "    \n",
    "    # scaler.inverse_transform(predicted_output.reshape(-1,1))\n",
    "    scaled_pred = pred_output.detach().numpy()[0, 0]\n",
    "    \n",
    "    # Create a dummy array with zeros for other features\n",
    "    dummy_array = np.zeros((1, 5))  # 5 features: Open, High, Low, Close, Volume\n",
    "    dummy_array[0, 3] = scaled_pred  # Put prediction in Close price position (index 3)\n",
    "    \n",
    "    # Now inverse transform\n",
    "    predicted_value = scaler.inverse_transform(dummy_array)[0, 3]  # Get only the Close price\n",
    "\n",
    "    print(f\"Predicted Close Price: ₹{predicted_value:.2f}\")\n",
    "    \n",
    "    # Optional: Compare with actual\n",
    "    actual_close = float(data['Close'].iloc[-1])\n",
    "    print(f\"Actual Close Price: ₹{actual_close:.2f}\")\n",
    "    print(f\"Prediction Error: ₹{abs(actual_close - predicted_value):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stock_scaler.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': num_epochs,\n",
    "    'loss': epoch_loss,\n",
    "}, 'stock_prediction_model.pth')\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'stock_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
